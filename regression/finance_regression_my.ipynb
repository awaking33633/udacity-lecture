{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load finance_regression.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"b\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )  # x:feature_test, y:reg.predict(feature_test)\n",
    "except NameError:\n",
    "    pass\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (29283125)>\n"
     ]
    }
   ],
   "source": [
    "#use ggplot\n",
    "from pandas import *\n",
    "from ggplot import *\n",
    "\n",
    "d = {'feature':Series(feature_train+feature_test),\n",
    "     'label':Series(target_train+target_test),\n",
    "     'group':Series(['train']*len(target_train)+['test']*len(target_test))}\n",
    "\n",
    "df = DataFrame(d)\n",
    "\n",
    "pl = ggplot(aes(x='feature',y='label',color='group'),df) + geom_point()\n",
    "# ggsave(filename='saveme.jpg',plot=pl)\n",
    "print pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! pip install ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from_dict(, orient='index') :orient default value is 'column' : orient='index', row \n",
    "#orient : {‘columns’, ‘index’}, default ‘columns’\n",
    "#The “orientation” of the data. If the keys of the passed dict should be the columns of the resulting DataFrame, \n",
    "#pass ‘columns’ (default). Otherwise if the keys should be rows, pass ‘index’.\n",
    "df_sb = DataFrame.from_dict(dictionary,orient='index')  #Construct DataFrame from dict of array-like or dicts, df_sb is DataFrame\n",
    "# df_sb = DataFrame.from_dict(dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METTS MARK', 'BAXTER JOHN C']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.keys()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bonus': 600000,\n",
       "  'deferral_payments': 'NaN',\n",
       "  'deferred_income': 'NaN',\n",
       "  'director_fees': 'NaN',\n",
       "  'email_address': 'mark.metts@enron.com',\n",
       "  'exercised_stock_options': 'NaN',\n",
       "  'expenses': 94299,\n",
       "  'from_messages': 29,\n",
       "  'from_poi_to_this_person': 38,\n",
       "  'from_this_person_to_poi': 1,\n",
       "  'loan_advances': 'NaN',\n",
       "  'long_term_incentive': 'NaN',\n",
       "  'other': 1740,\n",
       "  'poi': False,\n",
       "  'restricted_stock': 585062,\n",
       "  'restricted_stock_deferred': 'NaN',\n",
       "  'salary': 365788,\n",
       "  'shared_receipt_with_poi': 702,\n",
       "  'to_messages': 807,\n",
       "  'total_payments': 1061827,\n",
       "  'total_stock_value': 585062},\n",
       " {'bonus': 1200000,\n",
       "  'deferral_payments': 1295738,\n",
       "  'deferred_income': -1386055,\n",
       "  'director_fees': 'NaN',\n",
       "  'email_address': 'NaN',\n",
       "  'exercised_stock_options': 6680544,\n",
       "  'expenses': 11200,\n",
       "  'from_messages': 'NaN',\n",
       "  'from_poi_to_this_person': 'NaN',\n",
       "  'from_this_person_to_poi': 'NaN',\n",
       "  'loan_advances': 'NaN',\n",
       "  'long_term_incentive': 1586055,\n",
       "  'other': 2660303,\n",
       "  'poi': False,\n",
       "  'restricted_stock': 3942714,\n",
       "  'restricted_stock_deferred': 'NaN',\n",
       "  'salary': 267102,\n",
       "  'shared_receipt_with_poi': 'NaN',\n",
       "  'to_messages': 'NaN',\n",
       "  'total_payments': 5634343,\n",
       "  'total_stock_value': 10623258}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.values()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955</td>\n",
       "      <td>2902</td>\n",
       "      <td>2869717</td>\n",
       "      <td>4484442</td>\n",
       "      <td>1729541</td>\n",
       "      <td>4175000</td>\n",
       "      <td>126027</td>\n",
       "      <td>1407</td>\n",
       "      <td>-126027</td>\n",
       "      <td>1729541</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>304805</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>182466</td>\n",
       "      <td>257817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 salary to_messages deferral_payments total_payments  \\\n",
       "ALLEN PHILLIP K  201955        2902           2869717        4484442   \n",
       "BADUM JAMES P       NaN         NaN            178980         182466   \n",
       "\n",
       "                exercised_stock_options    bonus restricted_stock  \\\n",
       "ALLEN PHILLIP K                 1729541  4175000           126027   \n",
       "BADUM JAMES P                    257817      NaN              NaN   \n",
       "\n",
       "                shared_receipt_with_poi restricted_stock_deferred  \\\n",
       "ALLEN PHILLIP K                    1407                   -126027   \n",
       "BADUM JAMES P                       NaN                       NaN   \n",
       "\n",
       "                total_stock_value           ...           loan_advances  \\\n",
       "ALLEN PHILLIP K           1729541           ...                     NaN   \n",
       "BADUM JAMES P              257817           ...                     NaN   \n",
       "\n",
       "                from_messages other from_this_person_to_poi    poi  \\\n",
       "ALLEN PHILLIP K          2195   152                      65  False   \n",
       "BADUM JAMES P             NaN   NaN                     NaN  False   \n",
       "\n",
       "                director_fees deferred_income long_term_incentive  \\\n",
       "ALLEN PHILLIP K           NaN        -3081055              304805   \n",
       "BADUM JAMES P             NaN             NaN                 NaN   \n",
       "\n",
       "                           email_address from_poi_to_this_person  \n",
       "ALLEN PHILLIP K  phillip.allen@enron.com                      47  \n",
       "BADUM JAMES P                        NaN                     NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sb[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(feature_train,target_train)  # .fit(feature_train,target_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient: slope  [ 5.44814029]\n",
      "intercept  -102360.543294\n"
     ]
    }
   ],
   "source": [
    "print \"coefficient: slope \",clf.coef_\n",
    "print \"intercept \",clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you tested on the same data that you used to train : clf.score(feature_train,target_train) instead of clf.score(feature_test, target_test)\n",
    "Imagine you were a less savvy machine learner, and didn’t know to test on a holdout test set. Instead, you tested on the same data that you used to train, by comparing the regression predictions to the target values (i.e. bonuses) in the training data. What score do you find? You may not have an intuition yet for what a “good” score is; this score isn’t very good (but it could be a lot worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045509192699524359"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(feature_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4849924173685092"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now compute the score for your regression on the test data, like you know you should. What’s that score on the testing data? \n",
    "#If you made the mistake of only assessing on the training data, \n",
    "#would you overestimate or underestimate the performance of your regression?  mistakes using train data leads to overestimate.\n",
    "clf.score(feature_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are lots of finance features available, some of which might be more powerful than others in terms of predicting a person’s bonus. \n",
    "For example, suppose you thought about the data a bit and guess that the “long_term_incentive” feature, which is supposed to reward employees for contributing to the long-term health of the company, might be more closely related to a person’s bonus than their salary is.\n",
    "\n",
    "A way to confirm that you’re right in this hypothesis is to regress the bonus against the long term incentive, and see if the regression score is significantly higher than regressing the bonus against the salary. Perform the regression of bonus against long term incentive--what’s the score on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import pickle\n",
    "# sys.path.append(\"../tools/\")\n",
    "# from feature_format import featureFormat, targetFeatureSplit\n",
    "# dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "features_list = [\"bonus\", \"long_term_incentive\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = linear_model.LinearRegression()\n",
    "clf2.fit(feature_train,target_train)  # .fit(feature_train,target_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient: slope  [ 1.19214699]\n",
      "intercept  554478.756215\n"
     ]
    }
   ],
   "source": [
    "print \"coefficient: slope \",clf2.coef_\n",
    "print \"intercept \",clf2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.59271289994986387"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing previous (bonus, salary ) : -1.4849924173685092, this output  is bigger .Better score will produce better fit!!\n",
    "clf2.score(feature_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Better score will produce better fit( Using long_term_incentive to predict the bonus makes better score than using the salary to predict the bonus)\n",
    "If you had to predict someone’s bonus and you could only have one piece of information about them, would you rather know their salary or the long term incentive that they received?\n",
    "\n",
    "Better score will produce better fit\n",
    "\n",
    "This is a sneak peek of the next lesson, on outlier identification and removal. Go back to a setup where you are using the salary to predict the bonus, and rerun the code to remind yourself of what the data look like. You might notice a few data points that fall outside the main trend, someone who gets a high salary (over a million dollars!) but a relatively small bonus. This is an example of an outlier, and we’ll spend lots of time on them in the next lesson.\n",
    "\n",
    "A point like this can have a big effect on a regression: if it falls in the training set, it can have a significant effect on the slope/intercept if it falls in the test set, it can make the score much lower than it would otherwise be As things stand right now, this point falls into the test set (and probably hurting the score on our test data as a result). Let’s add a little hack to see what happens if it falls in the training set instead. Add these two lines near the bottom of finance_regression.py, right before plt.xlabel(features_list[1]):\n",
    "\n",
    "reg.fit(feature_test, target_test)  ###training(fitting) using test data, in which outliers may be inclued.\n",
    "\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"r\") \n",
    "\n",
    "Now we’ll be drawing two regression lines, one fit on the test data (with outlier) and one fit on the training data (no outlier). Look at the plot now--big difference, huh? That single outlier is driving most of the difference. What’s the slope of the new regression line?\n",
    "\n",
    "(That’s a big difference, and it’s mostly driven by the outliers. The next lesson will dig into outliers in more detail so you have tools to detect and deal with them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "    starter code for the regression mini-project\n",
    "    \n",
    "    loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project)\n",
    "\n",
    "    draws a little scatterplot of the training/testing data\n",
    "\n",
    "    you fill in the regression code where indicated\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True) #, \"long_term_incentive\"], remove_any_zeroes=True )\n",
    "\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"b\"\n",
    "\n",
    "\n",
    "\n",
    "### your regression goes here!\n",
    "### please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train,target_train)   #train(fit) with train data.\n",
    "\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )  #with test data, perform predict with the model which was trained.\n",
    "except NameError:\n",
    "    pass\n",
    "reg.fit(feature_test, target_test)\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"r\")\n",
    "\n",
    "\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.27410114])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The slope is about 2.27 after removing the outlier, which is a big difference from what we had before (about 5.4). \n",
    "#A small number of outliers makes a big difference!\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
